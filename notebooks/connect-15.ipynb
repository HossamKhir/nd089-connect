{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 15\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "It is an optimisation technique used to iteratively find the most appropriate\n",
    "weights for the model.\n",
    "\n",
    "First you define your architecture, and choose a loss metric (error/loss\n",
    "function), then you do feed forward.\n",
    "Then you find the error/loss, and feed it backward into your network, through\n",
    "the help of calculus (gradient), and chain rule.\n",
    "\n",
    "To do so, we define the metrics that we might use:\n",
    "\n",
    "---\n",
    "\n",
    "### Includes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for clean code, best practices\n",
    "from __future__ import annotations\n",
    "# we will use numpy for implementation\n",
    "import numpy as np\n",
    "\n",
    "# again, just for clean code\n",
    "from typing import Callable\n",
    "\n",
    "# set a seed for better debugging\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss metrics\n",
    "\n",
    "The error functions that might be used to tell how well a model performs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost functions\n",
    "# more here: https://builtin.com/machine-learning/common-loss-functions\n",
    "\n",
    "\n",
    "def mean_absolute_error(labels: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"returns the sum of squared errors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "\n",
    "    \"\"\"\n",
    "    m = len(labels)\n",
    "    return np.sum(np.abs(labels - predictions)) / m\n",
    "\n",
    "\n",
    "def mean_squared_error(labels: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"returns the mean squared error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "\n",
    "    \"\"\"\n",
    "    m = len(labels)\n",
    "    return np.sum((labels - predictions) ** 2) / (2 * m)\n",
    "\n",
    "\n",
    "def root_mean_squared_error(labels: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"returns the root mean squared error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(labels, predictions))\n",
    "\n",
    "\n",
    "def r2_score(labels: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"returns the coefficient of determination\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "    \"\"\"\n",
    "    mean = np.mean(labels)\n",
    "    ss_res = np.sum((labels - predictions) ** 2)\n",
    "    ss_tot = np.sum((labels - mean) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "\n",
    "def log_loss(labels: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"returns the log loss error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "    \"\"\"\n",
    "    labels = np.tile(labels, (len(labels), 1))\n",
    "    return np.sum(np.log(predictions) @ labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Above are the right way to define metrics, but since we need something simple for today's tutorial, we will define simpler metrics below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified for exercise\n",
    "def mean_absolute_error(error: np.ndarray) -> float:\n",
    "    \"\"\"returns the sum of squared errors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "\n",
    "    \"\"\"\n",
    "    m = len(error)\n",
    "    return np.sum(np.abs(error)) / m\n",
    "\n",
    "\n",
    "def mean_squared_error(error: np.ndarray) -> float:\n",
    "    \"\"\"returns the mean squared error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "\n",
    "    \"\"\"\n",
    "    m = len(error)\n",
    "    return np.sum(error**2) / (2 * m)\n",
    "\n",
    "\n",
    "def root_mean_squared_error(error: np.ndarray) -> float:\n",
    "    \"\"\"returns the root mean squared error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "We remember that neurons have the useful property of including non-linearity in \n",
    "calculations that allow neural networks to capture more complex features that\n",
    "other methods might not be able to capture.\n",
    "\n",
    "Here we define the most common activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "def relu(z: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"Rectified Linear Unit\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    if type(z) == float:\n",
    "        return max(0, z)\n",
    "    zeros = np.zeros(z.shape)\n",
    "    return np.max(np.c_[z, zeros], axis=1)\n",
    "\n",
    "\n",
    "def leaky_relu(z: float | np.ndarray, slope: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Leaky Rectified Linear Unit\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: np.ndarray\n",
    "    \"\"\"\n",
    "    return np.max(np.c_[z, slope * z], axis=1)\n",
    "\n",
    "\n",
    "def sigmoid(z: float | list | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"Sigmoid, the logistic function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Softmax\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: np.ndarray\n",
    "    \"\"\"\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "\n",
    "# NOTE: tanh could be provided by numpy through np.tanh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives\n",
    "\n",
    "Since we are going to need gradients and chain rule, it is best to define the\n",
    "derivatives of the activation function and the loss-metric\n",
    "\n",
    "---\n",
    "\n",
    "We start w/ derivatives of activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of activation functions\n",
    "class UndefinedDerivative(Exception):\n",
    "    \"\"\"Exception for when a function has no defined derivative at a certain\n",
    "    point\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def relu_prime(z: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    if type(z) == float:\n",
    "        if z == 0:\n",
    "            raise UndefinedDerivative(\"Undefined derivative\")\n",
    "        return 0 if z < 0 else 1\n",
    "    if np.any(z == 0):\n",
    "        raise UndefinedDerivative(\"Undefined derivative\")\n",
    "    return (z > 0).astype(np.int64)\n",
    "\n",
    "\n",
    "def leaky_relu_prime(z: float | np.ndarray, slope: float) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    if type(z) == float:\n",
    "        if z == 0:\n",
    "            raise UndefinedDerivative(\"Undefined derivative\")\n",
    "        return slope if z < 0 else 1\n",
    "    if np.any(z == 0):\n",
    "        raise UndefinedDerivative(\"Undefined derivative\")\n",
    "    return ((z < 0) * (slope - 1)) + 1\n",
    "\n",
    "\n",
    "def sigmoid_prime(z: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    sigma = sigmoid(z)\n",
    "    return sigma * (1 - sigma)\n",
    "\n",
    "\n",
    "def softmax_prime(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: np.ndarray\n",
    "    \"\"\"\n",
    "    e_z = np.exp(z)\n",
    "    total = np.sum(e_z)\n",
    "    return (e_z * (total - e_z)) / (total**2)\n",
    "\n",
    "\n",
    "def tanh_prime(z: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: float, np.ndarray\n",
    "    \"\"\"\n",
    "    return 1 - (np.tanh(z) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For implementation purposes, let's define a mapping between activations & their derivatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_PRIMES = {\n",
    "    relu: relu_prime,\n",
    "    leaky_relu: leaky_relu_prime,\n",
    "    sigmoid: sigmoid_prime,\n",
    "    softmax: softmax_prime,\n",
    "    np.tanh: tanh_prime,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define derivative for loss-metrics\n",
    "\n",
    "> the o/p of these derivatives is what was referred to in the Udacity classroom as **error term**, not the complete derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of cost simplified cost functions\n",
    "def mean_absolute_error_prime(\n",
    "    error=None,\n",
    "    activation_prime: float | Callable | np.ndarray = 1.0,\n",
    "    weighted_features: np.ndarray = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" \"\"\"\n",
    "    m = 1\n",
    "    if error:\n",
    "        m = len(error)\n",
    "    if callable(activation_prime):\n",
    "        activation_prime = activation_prime(weighted_features)\n",
    "    return -activation_prime / m\n",
    "\n",
    "\n",
    "def mean_squared_error_prime(\n",
    "    error: np.ndarray,\n",
    "    activation_prime: float | Callable | np.ndarray = 1.0,\n",
    "    weighted_features: np.ndarray = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" \"\"\"\n",
    "    # m = len(error)\n",
    "    m = len(error) if isinstance(error, np.ndarray) else 1\n",
    "    if callable(activation_prime):\n",
    "        activation_prime = activation_prime(weighted_features)\n",
    "    return (error * activation_prime) / m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This here are some random data & random weights for the simplest architecture, an\n",
    "i/p layer, a 1-neuron o/p layer\n",
    "\n",
    "> this is just for illustration purposes, the same way the classroom started simple, then drove more complex.\n",
    "\n",
    "> Could be a good exercise to first generalise for multi-output, then generalise for `DNN`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = 0.1\n",
    "# features\n",
    "x = np.array(list(range(1, 5)))\n",
    "# labels\n",
    "y = np.array((0.5))\n",
    "# initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "# TODO: try to update the code to define random weights if not provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define our gradient descent, note that while we are deriving the GD\n",
    "in classes, it is still the very same gradient descent code from the classroom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good OOP practice to define interfaces/abstract classes\n",
    "class AbstractGradientDescent:\n",
    "    def __init__(self, *args, **kwargs) -> AbstractGradientDescent:\n",
    "        pass\n",
    "\n",
    "    def backward(self, error: np.ndarray) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, features: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def step(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Vanilla gradient descent we all know and love\n",
    "class GradientDescent(AbstractGradientDescent):\n",
    "    def __init__(self, *args, **kwargs) -> GradientDescent:\n",
    "        # learning rate\n",
    "        self._lr = kwargs.get(\"learning_rate\", 0.01)\n",
    "        self._w = kwargs.get(\"weights\")\n",
    "        self._dw = np.zeros(self._w.shape)\n",
    "        # in case no activation is set, act like no non-linearity included\n",
    "        # NOTE: when expanding the logic for MLP/DNN, this should be per-layer\n",
    "        #   configuration\n",
    "        self._activation = kwargs.get(\"activation\", lambda x: x)\n",
    "        # loss metric\n",
    "        self._metric_prime = kwargs.get(\"loss_fn\", mean_squared_error_prime)\n",
    "        # derivative of activation could be passed as an argument, or extracted\n",
    "        #   from the global dictionary defined\n",
    "        self._activation_prime = kwargs.get(\n",
    "            \"activation_prime\",\n",
    "            ACTIVATION_PRIMES.get(self._activation, lambda x: x),\n",
    "        )\n",
    "        # define elements needed for zero_grad, and step functions\n",
    "        self._hidden = None\n",
    "        self._x = None\n",
    "\n",
    "    def backward(self, error: np.ndarray) -> None:\n",
    "        # calculate the gradient of the o/p wrt the weights\n",
    "        # self._dw = error * self._activation_prime(self._hidden)\n",
    "        self._dw = self._metric_prime(error, self._activation, self._hidden)\n",
    "\n",
    "    def forward(self, features: np.ndarray) -> np.ndarray:\n",
    "        # keep the input features for the complete gradient calculation\n",
    "        self._x = features\n",
    "        # keep the hidden layer o/p for use with gradient\n",
    "        self._hidden = features @ self._w\n",
    "        # the forward step, activation on hidden layer o/p\n",
    "        return self._activation(self._hidden)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        # update the weights\n",
    "        self._w += self._lr * self._dw * self._x\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        # clear the gradient calculated before\n",
    "        self._dw = np.zeros(self._w.shape)\n",
    "        if self._hidden is not None:\n",
    "            self._hidden = np.zeros(self._hidden.shape)\n",
    "        self._x = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6899744811276125 -0.1899744811276125\n",
      "0.6003125016027219 -0.10031250160272187\n",
      "0.5562880935734273 -0.056288093573427345\n",
      "0.5329953867405707 -0.032995386740570676\n",
      "0.5198431889101734 -0.019843188910173448\n",
      "0.5121147349894629 -0.012114734989462916\n",
      "0.5074634514314771 -0.007463451431477086\n",
      "0.5046233024344993 -0.004623302434499266\n",
      "0.5028736329575841 -0.002873632957584138\n",
      "0.5017898512687841 -0.0017898512687840595\n"
     ]
    }
   ],
   "source": [
    "optimiser = GradientDescent(learning_rate=.1, weights=w.copy(), activation=sigmoid)\n",
    "epochs = 10\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "    p = optimiser.forward(x)\n",
    "    e = y - p\n",
    "    optimiser.backward(e)\n",
    "    print(p, e)\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad\n",
    "\n",
    "There are ways to improve how quick your model should learn amongst those are:\n",
    "\n",
    "- Adaptive Learning Rate, and\n",
    "- Momentum-based Gradient Descent (later on that)\n",
    "\n",
    "The adaptive learning rate is simply a learning rate that changes according to\n",
    "some conditions.\n",
    "\n",
    "For `AdaGrad` (Adaptive Gradient), the condition is that the sparse features,\n",
    "which lead to slow learning rate, should have bigger learning rate than dense\n",
    "features.\n",
    "\n",
    "For more in detail on AdaGrad, check this [article](https://medium.com/konvergen/an-introduction-to-adagrad-f130ae871827)\n",
    "\n",
    "Eventually, that leads to usage of a slightly different update step\n",
    "\n",
    "$$\n",
    "W^{\\prime} = W + \\frac{\\alpha}{\\sqrt{\\upsilon_t}+\\varepsilon}\\nabla{W}\n",
    "\\\\\n",
    "\\upsilon_t=\\upsilon_{t-1} + (\\nabla{W})^2; \\upsilon_0=0\n",
    "$$\n",
    "\n",
    "where &alpha; is the initial learning rate defined by us,\n",
    "&epsilon; is a small number ($10^{-8}$) to avoid division by $0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad(GradientDescent):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that classifier to the test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = AdaGrad(learning_rate=10e-3, weights=w.copy(), activation=sigmoid)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "    p = optimiser.forward(x)\n",
    "    e = y - p\n",
    "    optimiser.backward(e)\n",
    "    print(p, e)\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "\n",
    "AdaGrad helped w/ the sparse features and their learning rate, but that led to\n",
    "some unintentional issue, the **vanishing gradient**, which is the gradient\n",
    "arrives at some point to $0$, so the weights stop updating afterwards, and that\n",
    "might happen before the minima.\n",
    "\n",
    "For `RMSProp` (Root Mean Square Propagation), we find a way to mitigate the\n",
    "effect of decaying learning rate, by throttling the rapid growth of\n",
    "$\\upsilon_t$. That is done through the concept of\n",
    "_Exponentially Weight Moving Average_ [EWMA](https://medium.com/mlearning-ai/exponentially-weighted-average-5eed00181a09)\n",
    "\n",
    "More details about RMSProp are in this [article](https://medium.com/optimization-algorithms-for-deep-neural-networks/rmsprop-fb992098fa6e)\n",
    "\n",
    "RMSProp keeps the same update equation, but alters the $\\upsilon_t$ equation\n",
    "\n",
    "$$\n",
    "\\upsilon_t = \\beta\\upsilon_{t-1} + (1-\\beta)(\\nabla{W})^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp(AdaGrad):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put this optimiser to the test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = RMSProp(learning_rate=5e-4, weights=w.copy(), activation=sigmoid)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "    p = optimiser.forward(x)\n",
    "    e = y - p\n",
    "    optimiser.backward(e)\n",
    "    print(p, e)\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaM\n",
    "\n",
    "As mentioned before, there is a method that allows for improving learning by\n",
    "leveraging _momentum_. It is similar to the momentum from mechanics.\n",
    "\n",
    "In simple words, as long as you are sliding down a hill, you gain momentum, once\n",
    "you reach a slightly less steep, or even uphill, this momentum drops.\n",
    "\n",
    "This might be helpful to avoid getting stuck at a local minimum.\n",
    "\n",
    "Now we have another way to help with optimisation, which is mixing both momentum\n",
    "& adaptive learning rate\n",
    "\n",
    "More info on AdaM in this [article](https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be)\n",
    "\n",
    "The new equations are quite different, 1st the weights are now updated by the\n",
    "means of the momentum, which in turn is based off the gradient, and still using\n",
    "the adaptive learning rate.\n",
    "\n",
    "$$\n",
    "m_t=\\beta_1\\upsilon_{t-1}+(1-\\beta_1)(\\nabla{W})\n",
    "\\\\\n",
    "\\upsilon_t=\\beta_2\\upsilon_{t-1}+(1-\\beta_2)(\\nabla{W})^2\n",
    "\\\\\n",
    "W^{\\prime}=W + \\frac{\\alpha}{\\sqrt{\\upsilon_t}+\\varepsilon}m_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaM(RMSProp):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final test, the adam optimiser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = AdaM(learning_rate=.01, weights=w.copy(), activation=sigmoid)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "    p = optimiser.forward(x)\n",
    "    e = y - p\n",
    "    optimiser.backward(e)\n",
    "    print(p, e)\n",
    "    optimiser.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eae71b2c053f62fccba4476524b45392e885e2d15a93fe6df3acae47c8fc97b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
