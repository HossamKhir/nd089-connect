{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 06\n",
    "\n",
    "## [Pandas](https://pandas.pydata.org/docs/reference/index.html)\n",
    "\n",
    "- [DataFrames](#dataframes)\n",
    "- [Exploring DataFrames](#exploring-dataframes)\n",
    "- [Sorting & Subsetting](#sorting--subsetting)\n",
    "  - [Sorting](#sorting)\n",
    "  - [Subsets](#subsets)\n",
    "- [Adding new columns](#adding-new-columns)\n",
    "- [Summary statistics](#summary-statistics)\n",
    "- [Counting](#counting)\n",
    "- [Grouped summary statistics](#grouped-summary-statistics)\n",
    "- [Indices](#indices)\n",
    "- [Slicing and subsets using loc & iloc](#slicing--subsets-using-loc--iloc)\n",
    "- [Missing values](#missing-values)\n",
    "- [Reading/writing DataFrames](#readingwriting-data-frames)\n",
    "\n",
    "### DataFrames\n",
    "\n",
    "Remember Python's `list`s? where you can put any \"object\" inside of these?\n",
    "\n",
    "What about NumPy's `ndarray`s? they should be of a specific contiguous type!\n",
    "\n",
    "Pandas' DataFrame is somewhat a mix of those two.\n",
    "Officially, it follows [R](https://cran.r-project.org/)'s original DataFrame.\n",
    "Where you can have mixed types of data, but structured.\n",
    "Meaning you can have **records** (rows) that have different types of data,\n",
    "and **features** (columns) that are of a single data type.\n",
    "\n",
    "It is made to handle **tabular** data, which is how data is most-likely represented.\n",
    "\n",
    "For an instance:\n",
    "\n",
    "- A survey about BMI `Body Mass Indicator` may require:\n",
    "  - ID of respondent, `int`\n",
    "  - Name of participant, `str`\n",
    "  - Height, (in metres), `float`, `m`\n",
    "  - Weight, (in kilograms), `float`, `kg`\n",
    "  - BMI, (calculated, $weight/height^2$), `float`, $kg/m^2$\n",
    "\n",
    "> There's a slight difference in the `BMI` formula for imperial units $lbs/in^2$\n",
    "\n",
    "So a single response have 3 different data types, (`int`, `str`, & `float`).\n",
    "But a whole survey, in a table, have columns of a single data type (`str` for all names, `float` for others)\n",
    "\n",
    "|id|name|height (m)|weight (kg)|bmi (kg/m^2)|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|John Doe|1.74|80|26.42|\n",
    "|2|Jane Doe|1.65|67|24.61|\n",
    "|&vellip;|&vellip;|&vellip;|&vellip;|&vellip;|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring DataFrames\n",
    "\n",
    "Pandas is basically built on top of 2 libraries `NumPy` and `Matplotlib`.\n",
    "A fraction of the methods of NumPy is still available within Pandas.\n",
    "Like `df.shape` should give you the size/shape of the DataFrame (or Series, more on that later)\n",
    "\n",
    "> `df` is a placeholder similar to `foo` or `arr` in case of NumPy\n",
    "\n",
    "Some new methods are available only to Pandas, like how to get the statistical summary of the DataFrame.\n",
    "Since there are rows and columns (and each has their own usage), you can get each on its own.\n",
    "You can also get a summary about the structure of the data set\n",
    "\n",
    "```python\n",
    "# get an overview of the set\n",
    "df.info()\n",
    "# get a statistical summary of the dataset\n",
    "df.describe()\n",
    "# get the columns' names\n",
    "df.columns\n",
    "# get the index identifiers\n",
    "df.index\n",
    "# retrieve some of first entries\n",
    "df.head()\n",
    "# get the last 6 records\n",
    "df.tail(n=6)\n",
    "\n",
    "df.sample(n=5)\n",
    "```\n",
    "\n",
    "As mentioned before, Pandas is built on top of NumPy, to get the NumPy representation of a DataFrame, use the `values` attribute\n",
    "\n",
    "```py\n",
    "df.values\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataframe\n",
    "\n",
    "df = get_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Your turn_\n",
    "\n",
    "In the next cell, try to get the statistical summary, columns' names, index identifiers, shape, and the NumPy representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO print the shape of the dataframe\n",
    "\n",
    "# TODO print the columns' names\n",
    "\n",
    "# TODO print the indices\n",
    "\n",
    "# TODO print the numpy representation\n",
    "\n",
    "# TODO get the statistical summary of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO have a look at the first 6 records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO show the last 5 values of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting & Subsetting\n",
    "\n",
    "#### Sorting\n",
    "\n",
    "Pandas allows sorting in two manners:\n",
    "\n",
    "- by index, and\n",
    "- by value\n",
    "\n",
    "The index sorting is straight forward, the `sort_index` method,\n",
    "but Pandas allows a composite index,\n",
    "an index composed of several columns.\n",
    "\n",
    "Sorting by value is quite similar, using `sort_values` method,\n",
    "which has optional argument `ascending` defaults to `True`,\n",
    "\n",
    "```py\n",
    "df.sort_values(\"height (m)\")\n",
    "df.sort_values(\"weigth (kg)\", ascending=False)\n",
    "```\n",
    "\n",
    "It is also possible to have sorting by multiple columns,\n",
    "the ordering happen in the order of the given tuple/list,\n",
    "and in that case, the `ascending` arguments could also be tuple/list,\n",
    "which matches the given columns to sort.\n",
    "\n",
    "```py\n",
    "df.sort_values([\"height (m)\", \"name\"]) # first sort by height, then by name\n",
    "# sort weight in ascending order, then name in descending\n",
    "df.sort_values([\"weight (kg)\", \"name\"], ascending=[True, False])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>year</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2007</td>\n",
       "      <td>46.859</td>\n",
       "      <td>135031164</td>\n",
       "      <td>2013.977305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2002</td>\n",
       "      <td>46.608</td>\n",
       "      <td>119901274</td>\n",
       "      <td>1615.286395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1997</td>\n",
       "      <td>47.464</td>\n",
       "      <td>106207839</td>\n",
       "      <td>1624.941275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1992</td>\n",
       "      <td>47.472</td>\n",
       "      <td>93364244</td>\n",
       "      <td>1619.848217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>1987</td>\n",
       "      <td>46.886</td>\n",
       "      <td>81551520</td>\n",
       "      <td>1385.029563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957</td>\n",
       "      <td>48.945</td>\n",
       "      <td>61325</td>\n",
       "      <td>860.736903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>Micronesia, Fed. Sts.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "      <td>62.599</td>\n",
       "      <td>60427</td>\n",
       "      <td>3495.176267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1952</td>\n",
       "      <td>46.471</td>\n",
       "      <td>60011</td>\n",
       "      <td>879.583586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "      <td>70.941</td>\n",
       "      <td>59461</td>\n",
       "      <td>4939.758007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977</td>\n",
       "      <td>71.830</td>\n",
       "      <td>59412</td>\n",
       "      <td>7390.359942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country continent  year  lifeExp        pop    gdpPercap\n",
       "2195                Nigeria    Africa  2007   46.859  135031164  2013.977305\n",
       "2194                Nigeria    Africa  2002   46.608  119901274  1615.286395\n",
       "2193                Nigeria    Africa  1997   47.464  106207839  1624.941275\n",
       "2192                Nigeria    Africa  1992   47.472   93364244  1619.848217\n",
       "2191                Nigeria    Africa  1987   46.886   81551520  1385.029563\n",
       "...                     ...       ...   ...      ...        ...          ...\n",
       "2531  Sao Tome and Principe       NaN  1957   48.945      61325   860.736903\n",
       "1933  Micronesia, Fed. Sts.       NaN  1972   62.599      60427  3495.176267\n",
       "2530  Sao Tome and Principe       NaN  1952   46.471      60011   879.583586\n",
       "64                    Aruba       NaN  1972   70.941      59461  4939.758007\n",
       "65                    Aruba       NaN  1977   71.830      59412  7390.359942\n",
       "\n",
       "[3312 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: sort the data frame by indices\n",
    "\n",
    "# TODO: sort the data frame by a single column of your choice\n",
    "\n",
    "# TODO: sort the data frame by an arbitrary number of columns, have them differ\n",
    "#   in order (asc/desc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsets\n",
    "\n",
    "The most straight forward shape of subset in Pandas is selecting columns,\n",
    "with the syntax of indexing, in such case,\n",
    "you end up with a `pandas.Series` object, with a similar index to the original\n",
    "data frame.\n",
    "\n",
    "```py\n",
    "weights = df[\"weight (kg)\"]\n",
    "# weights is a pandas Series now, w/ the same index of the original df dataframe\n",
    "```\n",
    "\n",
    "It is also possible to subset a data frame into another data frame, i.e. subset\n",
    "by multiple columns.\n",
    "\n",
    "```py\n",
    "# NOTE: it is preferred to have your subset columns as separate variable\n",
    "subset = [\"name\", \"height\"] \n",
    "small_df = df[subset]\n",
    "\n",
    "# NOTE: it is also possible to have a dataframe of a single variable/column\n",
    "#   by subsetting w/ a list of a single column\n",
    "weights = df[[\"weight (kg)\"]] # notice the inner square brackets\n",
    "```\n",
    "\n",
    "Same as with NumPy arrays, Pandas series can apply vectorised operations like\n",
    "algebraic (`+`, `-`, `*`, etc&#8230;), inequality (`>`, `>=`, etc&#8230;),\n",
    "equality (`==`, `!=`), bitwise (`|`, `&`, `^`, etc&#8230;), or logical (`and`,\n",
    "`or`, `not`).\n",
    "\n",
    "Also, same as NumPy, Pandas series & data frames can be indexed by a boolean\n",
    "collection of the same length.\n",
    "\n",
    "```py\n",
    "target_weight = 65.0\n",
    "idx_target = df[\"weight (kg)\"] > target_weight\n",
    "# now idx_target is a Series of booleans, of the same length of the dataframe\n",
    "target = df[idx_target]\n",
    "# now target is a subset of df where weights are heavier than target_weight\n",
    "\n",
    "jane_does = df[df[\"name\"] == \"Jane Doe\"] # bad way\n",
    "# alternatively\n",
    "idx_jane_doe = df[\"name\"].str.lower() == \"jane doe\"\n",
    "jane_does = df[idx_jane_doe]\n",
    "\n",
    "target_jane_does = df[idx_target & idx_jane_doe]\n",
    "```\n",
    "\n",
    "That's great, but what about multiple values, like, I want both `John Doe` and\n",
    "`Jane Doe`? of course a logically combined index would work, but Pandas provide\n",
    "something special for that particular usage, the `isin` (is-in) method\n",
    "\n",
    "```py\n",
    "idx_does = df[\"name\"].str.lower().isin([\"john doe\", \"jane doe\"])\n",
    "does = df[idx_does]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: year, dtype: bool (3312,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "3307    True\n",
       "3308    True\n",
       "3309    True\n",
       "3310    True\n",
       "3311    True\n",
       "Name: continent, Length: 3312, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: get a series of continents\n",
    "\n",
    "# TODO: get a dataframe of continents\n",
    "\n",
    "# TODO: get a dataframe of countries & continents\n",
    "\n",
    "# TODO: get a boolean index for years past 1970\n",
    "\n",
    "# TODO: use the boolean index and get a dataframe that has years after 1970\n",
    "\n",
    "# TODO: get a dataframe where lifeExp is above 25.0 and year is before 1985\n",
    "\n",
    "# TODO: get a dataframe (using isin) that has African & Asian countries only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new columns\n",
    "\n",
    "Same like dictionaries, to add new columns, apply the operation you would like\n",
    "on the data frame, then use a new name inside square brackets to assign new\n",
    "column\n",
    "\n",
    "```py\n",
    "# remember how BMI is calculated, not gathered?\n",
    "df[\"bmi (kg/m^2)\"] = df[\"weight (kg)\"] / (df[\"height (m)\"] ** 2)\n",
    "# now, the new columns bmi (kg/m^2) is created\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "\n",
    "Pandas series & data frames offer many methods for statistical summarisation,\n",
    "that only applies on integers & floats, and sometimes could work for timestamps.\n",
    "Those include `min`, `max`, `mean`, `median`, `var` for _variance_, `std` for\n",
    "_standard deviation_, `sum`, `quantile`, etc&#8230;\n",
    "\n",
    "Also, pandas offer accumulated statistics, most have the prefix `cum` for\n",
    "_cumulative_, like `cumsum`, `cummin`, `cummax`, `cumprod` for\n",
    "_cumulative product_\n",
    "\n",
    "```py\n",
    "df[\"height (m)\"].min() # minimum height\n",
    "df[\"weight (kg)\"].mean() # average weight\n",
    "\n",
    "numeric = [\"height (m)\", \"weight (kg)\"]\n",
    "\n",
    "df[numeric].median() # median value per column\n",
    "\n",
    "df[\"height (m)\"].cumsum() # cumulative sum of heights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform any statistical summary operation you'd like, or multiple if\n",
    "#   you wish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting\n",
    "\n",
    "To obtain counts of available instance within a series or a data frame, use\n",
    "`value_counts` method.\n",
    "The methods also accepts arguments, like `sort` to sort the findings of the\n",
    "counts, or `normalize` to have the counts as proportions (counting sums to $1$)\n",
    "\n",
    "```py\n",
    "df[\"name\"].value_counts() # gets the counts of values in name series\n",
    "\n",
    "col_names = [...]\n",
    "# gets the counts of each combination of values in columns\n",
    "df[col_names].value_counts()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: count the country column\n",
    "\n",
    "# TODO: count the country+continent columns\n",
    "\n",
    "# TODO: count the continent columns, sorted\n",
    "\n",
    "# TODO: count the country+year columns in proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped summary statistics\n",
    "\n",
    "Pandas allows you to group by certain column(s), and aggregate the other values,\n",
    "and aggregation is meant for summary statistics, like `min`, `mean`, `std`, etc&#8230;\n",
    "\n",
    "```py\n",
    "df.groupby(\"name\")[\"height (m)\"].mean()\n",
    "\n",
    "# grouping could be multiple columns\n",
    "df.groupby([\"name\", \"height (m)\"])[\"weight (kg)\"].std()\n",
    "\n",
    "# ADVANCED: using the agg method\n",
    "df.groupby(\"name\")[[\"height (m)\", \"weight (kg)\"]].agg([min, max, mean])\n",
    "df.groupby(\"name\")[[\"height (m)\", \"weight (kg)\"]].agg({\"height (m)\":mean,\n",
    "\"weight (kg)\":max})\n",
    "```\n",
    "\n",
    "> Extra: try reading about `pivot_table`, a relatable method in grouped summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform summary statistics on grouped continents\n",
    "\n",
    "# TODO: group by year, and perform some summary statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices\n",
    "\n",
    "Most data files assign no importance to index, so you find these data sets with\n",
    "no specific index. Pandas default is to assign an integer index to those.\n",
    "\n",
    "But some other data sets have important index (e.g. time-series), so these\n",
    "should have the specified column as index. That's achievable using `set_index`\n",
    "method of the data frame.\n",
    "\n",
    "The `set_index` have an argument `inplace`, which is optional and defaults to\n",
    "`False`, which makes this method an out-of-place operation (i.e. the output of\n",
    "this method needs to be saved in a variable or lost otherwise). Setting\n",
    "`inplace=True` makes it an in-place operation, and the call to the method needs\n",
    "not be assigned a new variable.\n",
    "\n",
    "Also, you can have a composite (or **hierarchical**) indices (i.e. an index\n",
    "composed of multiple columns), `set_index` then receives a list, or tuple of\n",
    "column names.\n",
    "\n",
    "Indexing hierarchical indices requires either a tuple or a list of tuples.\n",
    "\n",
    "Now since the index is a column itself, sorting the index would be done with\n",
    "`sort_index` method. Arguments include `inplace`, `axis`, `ascending`, and\n",
    "`level`. `level` is used with hierarchical indices, to specify the order of\n",
    "sorting on the components of the index, the default that sorting is done on the\n",
    "order of the columns as stated in `set_index`.\n",
    "\n",
    "If you'd like to revert back to default integer indexing, use the `reset_index`\n",
    "method, which also has the `inplace` argument with the same default `False`.\n",
    "Another argument is `drop` which defaults to `False`. Setting `drop=True` resets\n",
    "the index, and removes the column(s) that used to be index.\n",
    "\n",
    "```py\n",
    "col_name = \"...\" # insert a column name\n",
    "new_df = df.set_index(col_name) # out-of-place\n",
    "\n",
    "df.set_index(col_name, inplace=True) # in-place, no need to new variables\n",
    "# retrieving using new index\n",
    "record = df.loc[\"value\"] # more on loc later\n",
    "\n",
    "col_names = (\"first_col\", \"second_col\")\n",
    "df.set_index(col_names, inplace=True) # in-place, composite index\n",
    "# using new indices\n",
    "record = df.loc[(\"value1\", \"value2\")]\n",
    "records = df.loc[[(\"value1.1\", \"value1.2\"), (\"value2.1\", \"value2.2\")]]\n",
    "\n",
    "df.sort_index(level=(\"second_col\", \"first_col\"), ascending=(True, False))\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set the continent as index, out-of-place, and keep it in a variable\n",
    "\n",
    "# TODO: sort the continent ascending & descending\n",
    "\n",
    "# TODO: reset the index on the new variable, in-place\n",
    "\n",
    "# TODO: set country + continent as index, on new variable, in-place\n",
    "\n",
    "# TODO: sort the indices on the new data frame, use the ascending and level args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing & Subsets using `loc` & `iloc`\n",
    "\n",
    "As you may have noticed, using square brackets `[]` for slicing mainly slices columns,\n",
    "and to slice up rows, we used boolean series or arrays of the complete length of the data frame.\n",
    "\n",
    "But Pandas offers a utility to do more with slicing the `loc` and `iloc`.\n",
    "The main difference between those two, is one works directly on the index `loc`, and the other works with integer indices `iloc`, but that doesn't mean they are exclusive, it just means, if you need the 10th entry into your data set, but don't know its actual index, then use `iloc`.\n",
    "\n",
    "Using `loc` (and `iloc`) allows for using the slicing techniques of python, like `[2:30:2]` to get the data from 3rd entry to the 19th with steps of two.\n",
    "Also, with string index, it could work to use `[\"Alice\":\"Martin\"]`, only difference here, is that this now is inclusive (you'd get `Martin` in your results).\n",
    "\n",
    "It gets tricky around hierarchical indices, as you'd need to use tuples inside your indexing.\n",
    "\n",
    "Both `loc` and `iloc` could apply the NumPy slicing, separating dimensions/axis with commas, like `df.iloc[:,:3]` gives you all the records, and keeps the first 3 columns, regardless of their names. It is still applicable to `loc` as well, like `df.loc[:,\"height (cm)\", \"weight (kg)\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use loc to slice columns\n",
    "\n",
    "# TODO: use iloc to slice arbitrarily across index, columns, and both\n",
    "\n",
    "# TODO: create a dataframe with country + continent as indices\n",
    "# TODO: on the new dataframe, use loc to slice on index, columns, and both\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Some data gathering processes could have an optional part, like in the survey for BMI, you could have a field that says:\n",
    "`I identify as...` and followed by a drop-down or a list of choices. One of the choices could be `I prefer not to disclose that`.\n",
    "At that point, such piece of information is unkown, so it is, in a sense, missing.\n",
    "\n",
    "Missing values in Pandas (or data science in general) are called `null`s or `na`s.\n",
    "\n",
    "To check if your set has missing data, use the `isna` or `isnull` methods.\n",
    "Those return a boolean data frame (or a series if applied on a series), that has the same shape of the object called them.\n",
    "If a value is missing (an `na`), then in its place (same index, and column) you'd find `True`, or `False` otherwise.\n",
    "\n",
    "Dealing with missing values is a tricky subject for data scientists, and there are several possibilities:\n",
    "\n",
    "1. Get rid of the record that holds missing values.\n",
    "2. Fill in all missing values by a single value.\n",
    "3. Fill in missing values by interpolation & extrapolation.\n",
    "4. etc&#8230;\n",
    "\n",
    "To get rid of a record is technically called `drop`ping them.\n",
    "The method to do so is called `dropna`. It accepts an argument `axis`, that would drop on columns or rows.\n",
    "Setting `axis=0` (the default) drops the records (rows) that hold `NA`s. `axis=1` drops the columns that do,\n",
    "which happens less often.\n",
    "\n",
    "To fill values, either by a single value or a method, use the `fillna` method. The keywords determine how it'd work.\n",
    "\n",
    "- Use `value` to fill with a certain value (or some EXTRA options)\n",
    "- Use `method` along with `axis` to fill missing values using existing ones\n",
    "\n",
    "Methods allow for assuming what missing data could be, methods could be:\n",
    "\n",
    "- back-fill\n",
    "- forward-fill\n",
    "\n",
    "Back-fill uses next few observations to assume the current, the forward-fill is the opposite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading/Writing data frames\n",
    "\n",
    "The most common format for saving on disks with pandas is the `CSV` or\n",
    "comma-separated value. These files contain each record (row) on a line, and the\n",
    "line composes of _ordered values_ (that later become columns), each value\n",
    "separated from the the others by a single comma. There are other variants, but\n",
    "not that common like `tsv` which is Tab-separated values, the only difference\n",
    "really is the values are separated by a tab character `\\t`. In fact, you can\n",
    "extend that into any character (or sequence of character) separated files.\n",
    "\n",
    "Pandas provide specific functions to read files, most common are `read_csv`, &\n",
    "`read_excel` which obviously reads excel files (but we won't cover that now)\n",
    "\n",
    "> N.B: `read_excel` requires a specific python module to be installed.\n",
    "\n",
    "If you check the documentation for `read_csv`, (and other read functions), you'd\n",
    "find a dozen arguments.\n",
    "\n",
    "- `index_col`: you can specify the index column(s), it is 0-based index\n",
    "- `columns`: allows you to specify which columns to read\n",
    "- `sep`: the separator used, that makes this function capable of reading `tsv` too\n",
    "- `header`: control the approach for reading header. Some data sets are simple and don't use a header, so using `None` ensures that the first line doesn't get mistaken for a header.\n",
    "- etc&#8230;\n",
    "\n",
    "To write/save a data frame, you have almost the same formats as read, but with\n",
    "`to` in place of `read` prefix, and those are methods on data frames, not\n",
    "functions, e.g. `to_csv`. Also these methods have most of the arguments of the\n",
    "read functions, with slight difference on the purpose.\n",
    "\n",
    "- `index`: a boolean that defaults to `True` and it allows keeping the index (row names). Set it to false if you don't need that.\n",
    "- `sep`: the separator to use, setting that to `\\t` allows you to save into `tsv`\n",
    "- `na_rep`: how to represent null/missing values\n",
    "- etc&#8230;\n",
    "\n",
    "```py\n",
    "# to read a csv file\n",
    "io_uri = \"path/to/file.csv\" # could be a URL too\n",
    "df = pd.read_csv(io_uri) # using defaults\n",
    "\n",
    "io_tsv = \"path/to/file.tsv\"\n",
    "df_tsv = pd.read_csv(io_tsv, sep=\"\\t\")\n",
    "\n",
    "# to save a dataframe to a csv file\n",
    "df.to_csv(\"target/file/path.csv\", index=False) # use default sep=\",\", and ignores index\n",
    "\n",
    "df.to_csv(\"location/path.tsv\", sep=\"\\t\") # saves to a tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the following URL to load the data set again\n",
    "gapminder_uri = (\n",
    "    \"https://github.com/jennybc/gapminder/raw/main/data-raw/04_gap-merged.tsv\"\n",
    ")\n",
    "\n",
    "# TODO: save the data loaded remotely, on your local machine, drop the index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
