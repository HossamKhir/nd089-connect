{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 05\n",
    "\n",
    "## [NumPy](https://numpy.org/doc/)\n",
    "\n",
    "### Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import numpy w/ the common alias np\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (9, 2)\n",
      "[ 5  5  5  5  5  5 12 12 12]\n",
      "[   3    5 1983]\n",
      "[[   5 2002]\n",
      " [   5 2005]\n",
      " [  12 2015]\n",
      " [  12 2017]]\n",
      "[[   1    2    3    4    5    6    7    8    9]\n",
      " [   5    5    5    5    5    5   12   12   12]\n",
      " [1977 1980 1983 1999 2002 2005 2015 2017 2019]] [[   1    2    3    4    5    6    7    8    9]\n",
      " [   5    5    5    5    5    5   12   12   12]\n",
      " [1977 1980 1983 1999 2002 2005 2015 2017 2019]] [[   1    2    3    4    5    6    7    8    9]\n",
      " [   5    5    5    5    5    5   12   12   12]\n",
      " [1977 1980 1983 1999 2002 2005 2015 2017 2019]]\n",
      "[   1    5 1983]\n",
      "[   5 1980]\n",
      "[   3    5 2002]\n",
      "[   1    2    3    4    5    6    7    8    9   12 1977 1980 1983 1999\n",
      " 2002 2005 2015 2017 2019]\n",
      "[[   7   12 2015]\n",
      " [   8   12 2017]\n",
      " [   9   12 2019]]\n",
      "[9 9 1 8 5 0 3 9]\n",
      "[0 1 3 5 8 9 9 9]\n",
      "[0 1 3 5 9]\n",
      "[0 1 3 4 5 7 8 9]\n",
      "[8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [1, 1],\n",
       "        [3, 3],\n",
       "        [5, 4],\n",
       "        [8, 4],\n",
       "        [9, 5],\n",
       "        [9, 7],\n",
       "        [9, 9]]),\n",
       " array([[0, 7],\n",
       "        [1, 4],\n",
       "        [3, 4],\n",
       "        [1, 5],\n",
       "        [5, 8],\n",
       "        [0, 9],\n",
       "        [9, 9],\n",
       "        [3, 9]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [1977, 1980, 1983, 1999, 2005, 2015, 2017, 2019]\n",
    "\n",
    "# TODO: create a numpy ndarray from years list\n",
    "years = np.array(years, dtype=np.int32)  # this overrides the years list\n",
    "# but we don't really need it\n",
    "# NOTE: best practice is to avoid overriding variables\n",
    "\n",
    "# TODO: create a numpy array of 6 entries all of value 5, and type int, call it\n",
    "# months\n",
    "# NOTE: you may use numpy's built-in API or use the vectorised operations\n",
    "months = np.full((6,), 5)\n",
    "alt_months = 5 * np.ones((6,))\n",
    "\n",
    "# TODO: get the lowest entry in the years array\n",
    "low_year = years.min()  # also max, mean, std `standard deviation`\n",
    "# OR:\n",
    "low_year = np.min(years)  # also max, mean, std\n",
    "\n",
    "# TODO: insert 2002 in 5th **location** (not index) of the years array\n",
    "years = np.insert(years, 4, 2002)\n",
    "\n",
    "# TODO: insert 12 three times at the end of the months array\n",
    "months = np.append(months, [12] * 3)\n",
    "\n",
    "# TODO: create a new ndarray, that has both arrays in\n",
    "#   rows\n",
    "dates = np.vstack([months, years])\n",
    "# OR:\n",
    "# dates = np.r_[months, years]\n",
    "#   columns, and let's keep that one as dates\n",
    "dates = np.hstack([months.reshape((-1, 1)), years.reshape((-1, 1))])\n",
    "# OR:\n",
    "# dates = np.c_[months, years]\n",
    "\n",
    "# TODO: print the number of dimensions of the dates matrix, and the dimensions\n",
    "# themselves\n",
    "print(dates.ndim, dates.shape)\n",
    "\n",
    "# TODO: create an ascending array starting at 1 and ending at the number of rows\n",
    "# in the dates matrix, using only numpy, named idx\n",
    "n, _ = dates.shape\n",
    "idx = np.arange(1, n + 1).reshape(n, 1)\n",
    "\n",
    "# TODO: add idx to the left of the dates matrix\n",
    "dates = np.hstack([idx, dates])\n",
    "\n",
    "# TODO in the dates matrix\n",
    "#   slice for the 2nd column\n",
    "print(dates[:, 1])\n",
    "#   slice for the 3rd row\n",
    "print(dates[2])  # OR: dates[2,:], but we can omit latter dimensions\n",
    "#   slice for values in 5th to 8th row, 2nd to 3rd column\n",
    "print(dates[4:8, 1:3])\n",
    "\n",
    "# TODO: save the dates array to dates.npy file\n",
    "np.save(\"dates.npy\", dates)\n",
    "\n",
    "# TODO: get the transpose of the dates array, and reshape it into 3D\n",
    "print(np.transpose(dates), dates.T, dates.transpose())\n",
    "\n",
    "# TODO: make a copy of the dates matrix, named dup, and replace values between\n",
    "# 7th row to last row with random floats\n",
    "dup = np.copy(dates)\n",
    "dup = dup.astype(float)\n",
    "\n",
    "randfloats = np.random.random((3, 3))\n",
    "dup[6:] = randfloats\n",
    "\n",
    "# TODO: get the main diagonal of dates array\n",
    "print(np.diag(dates))\n",
    "\n",
    "# TODO: get the 1st diagonal above the main from dates\n",
    "print(np.diag(dates, 1))\n",
    "# TODO: get the 2nd diagonal below the main from dates\n",
    "print(np.diag(dates, -2))\n",
    "\n",
    "# TODO: get the unique values from dates\n",
    "print(np.unique(dates))\n",
    "\n",
    "# TODO: filter the dates for rows where months are strictly greater than 5\n",
    "gt_5 = months > 5\n",
    "print(dates[gt_5])\n",
    "\n",
    "# TODO: create an array of random integers of size 8, called randi\n",
    "randi = np.random.randint(0, 10, (8,))\n",
    "\n",
    "# TODO: sort randi, out-of-place & in-place\n",
    "out_of_place = np.sort(randi)\n",
    "print(randi, out_of_place, sep=\"\\n\")\n",
    "randi.sort()\n",
    "\n",
    "# TODO: create another random integers array, called marti\n",
    "marti = np.random.randint(0, 10, (8,))\n",
    "\n",
    "# TODO: find intersection, union & difference amongst randi & marti\n",
    "print(np.intersect1d(randi, marti))\n",
    "print(np.union1d(randi, marti))\n",
    "print(np.setdiff1d(randi, marti))\n",
    "\n",
    "# TODO: combine both randi & marti as columns into rick, and sort on both axes\n",
    "rick = np.c_[randi, marti]\n",
    "np.sort(rick, axis=0), np.sort(rick, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((4, 4))\n",
    "\n",
    "# TODO: find the mean, standard deviation, & median of arr\n",
    "flat_mean = np.mean(arr)\n",
    "flat_std = np.std(arr)\n",
    "flat_median = np.median(arr)\n",
    "\n",
    "row_mean = np.mean(arr, axis=1)\n",
    "row_std = np.std(arr, axis=1)\n",
    "row_median = np.median(arr, axis=1)\n",
    "\n",
    "col_mean = np.mean(arr, axis=0)\n",
    "col_std = np.std(arr, axis=0)\n",
    "col_median = np.median(arr, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Broadcasting](https://numpy.org/devdocs/user/basics.broadcasting.html)\n",
    "\n",
    "Simply put, the ability to (automatically) match sizes of arrays\n",
    "\n",
    "---\n",
    "\n",
    "in linear algebra, an operations like $a * \\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{bmatrix}$ is completely valid & results in $\\begin{bmatrix} ab_{11} & ab_{12} \\\\ ab_{21} & ab_{22}\\end{bmatrix}$.\n",
    "\n",
    "On the other hand, operation like $a * \\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{bmatrix}$ is invalid, because addition requires either 2 scalars, or 2 vectors of identical dimensions, like $\\begin{bmatrix}a_{11} \\\\ a_{21}\\end{bmatrix}+\\begin{bmatrix}b_{11} \\\\ b{21}\\end{bmatrix}\\to\\begin{bmatrix}a_{11}+b_{11}\\\\a{21}+b_{21}\\end{bmatrix}$.\n",
    "\n",
    "Yet if tried the scalar $a$ + matrix $B$ in `numpy` it works. As you might have guessed already, it works because internally `numpy` found a way to match shapes to cover the rule of linear algebra. That's precisely the idea of broadcasting.\n",
    "\n",
    "On checking the documentation, you are provided w/ the simplest rule: start out from the rightmost dimension and work your way to the left. If the dimensions is $1$ or matches, then it is broadcast-able.\n",
    "\n",
    "If the one of the arrays have less dimensions, missing ones on the left can be assumed to be 1 (which is mathematically correct).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: optional, try to write a function to check for broadcasting using your\n",
    "# own understanding\n",
    "\n",
    "# We will leverage only the ones function just to demonstrate the broadcasting\n",
    "# TODO: without running the cell, comment out what you believe would violate\n",
    "# broadcasting rules\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = np.array([2.0, 2.0, 2.0])\n",
    "a + b\n",
    "\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = 2.0\n",
    "a + b\n",
    "\n",
    "a = np.ones((256, 256, 3))\n",
    "b = np.ones((3,))\n",
    "a * b\n",
    "\n",
    "a = np.ones((8, 1, 6, 1))\n",
    "b = np.ones((7, 1, 5))\n",
    "a + b\n",
    "\n",
    "a = np.ones((5, 4))\n",
    "b = 1.0\n",
    "a + b\n",
    "\n",
    "b = np.ones((4,))\n",
    "a + b\n",
    "\n",
    "a = np.ones((15, 3, 5))\n",
    "b = np.ones((15, 1, 5))\n",
    "a + b\n",
    "\n",
    "b = np.ones((3, 5))\n",
    "a + b\n",
    "\n",
    "b = np.ones((3, 1))\n",
    "a + b\n",
    "\n",
    "a = np.ones((4,))\n",
    "b = np.ones((3,))\n",
    "# a + b\n",
    "\n",
    "a = np.ones((2, 1))\n",
    "b = np.ones((8, 4, 3))\n",
    "# a + b\n",
    "\n",
    "a = np.ones((4, 3))\n",
    "b = np.ones((3))\n",
    "a + b\n",
    "\n",
    "b = np.ones((3, 1))\n",
    "# a + b\n",
    "\n",
    "b = np.ones((4,))\n",
    "# a + b\n",
    "\n",
    "a = np.ones((4, 1))\n",
    "b = np.ones((1, 3))\n",
    "a + b\n",
    "\n",
    "a = np.ones((10, 3))\n",
    "b = np.ones((5, 1, 3))\n",
    "a + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For practice & review, we will try to implement `PCA` (Principle Component Analysis) algorithm\n",
    "\n",
    "## PCA\n",
    "\n",
    "> For quick reference, check [this video](https://www.youtube.com/watch?v=dsOyN46exG0), and [this video](https://www.youtube.com/watch?v=xB7-b6FSANA) from [Udacity's YouTube](https://www.youtube.com/c/Udacity) channel\n",
    "\n",
    "![pca_gif](http://www.billconnelly.net/wp-content/uploads/2021/05/PCA1-smaller-smaller.gif)\n",
    "\n",
    "### Steps for PCA\n",
    "\n",
    "1. **Standardise** the feature set\n",
    "2. Calculate **covariance matrix** for _standardised_ set\n",
    "3. Calculate **eigenvectors** & **eigenvalues** for _covariance matrix_\n",
    "4. Sort _eigenvalues_ & _eigenvectors_\n",
    "5. **Pick top $k$** from sorted _eigenvalues_, and form a matrix from corresponding _eigenvectors_\n",
    "6. **Transform** _standardised_ set using the _k-eigenvectors_ matrix\n",
    "\n",
    "> First try each step on its own, then combine them into a subroutine/function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we need the os module for path creation\n",
    "import os\n",
    "\n",
    "# NOTE: define globals/constants\n",
    "DATA_PATH = \"../data/raw/toy\"\n",
    "RAW_DATA_FILE = \"raw.npy\"\n",
    "STD_DATA_FILE = \"standard.npy\"\n",
    "COV_MAT_FILE = \"covariance.npy\"\n",
    "EIG_VECT_FILE = \"e_vect.npy\"\n",
    "EIG_VAL_FILE = \"e_val.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 6, 9, 1],\n",
       "       [3, 7, 4, 9],\n",
       "       [3, 5, 3, 7],\n",
       "       [5, 9, 7, 2],\n",
       "       [4, 9, 2, 9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: read in the toy data set 'raw.npy' located at DATA_PATH, save it into\n",
    "# variable called raw\n",
    "raw = np.load(os.path.join(DATA_PATH, RAW_DATA_FILE))\n",
    "raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation is the process of ensuring the data set at hand has a mean of $0$ and a standard deviation of $1$\n",
    "\n",
    "The formula is\n",
    "\n",
    "$$\n",
    "X_{std} = \\frac{X-\\bar{X}}{\\sigma_X}\n",
    "$$\n",
    "\n",
    "> NOTE: this operation is done on feature level (i.e. done on column level, you'd use the axis argument w/ `numpy`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: standardise the raw set data, then read & compare w/ standardised data\n",
    "# TODO: find the mean\n",
    "mean = np.mean(raw, axis=0)\n",
    "\n",
    "# TODO: find the standard deviation\n",
    "std = np.std(raw, axis=0)\n",
    "\n",
    "# TODO: apply the formula\n",
    "standard = (raw - mean) / std\n",
    "\n",
    "# TODO: read the standard data set\n",
    "std_set = np.load(os.path.join(DATA_PATH, STD_DATA_FILE))\n",
    "\n",
    "# TODO: compare the values\n",
    "# HINT: use numpy.all\n",
    "np.all(std_set == standard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the standardised set is calculated, time to find the covariance\n",
    "\n",
    "Covariance is a bivariate moment, which measures how closely change in one variable affects the other.\n",
    "\n",
    "- A covariance of $1$ (which is covariance of a variable w/ itself) means highly positively related, \n",
    "- covariance of $0$ is no relation, and \n",
    "- $-1$ is highly negatively related.\n",
    "\n",
    "\n",
    "The formula is\n",
    "\n",
    "$$\n",
    "\\delta_{x,y}=\\frac{1}{n-1}\\Sigma_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})\n",
    "$$\n",
    "\n",
    "> NOTE: we will not implement this formula, as `numpy` already has a ready-made function for it, use the documentation (or search engine) to find it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: search the documentation (or use search engine) to find which numpy\n",
    "# function can be used to find covariance, and use to find covariance of the\n",
    "# standard set\n",
    "cov = np.cov(standard, rowvar=False)\n",
    "cov\n",
    "\n",
    "# TODO: read in the covariance matrix and compare w/ your output\n",
    "covariance = np.load(os.path.join(DATA_PATH, COV_MAT_FILE))\n",
    "cov == covariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, you've found the covariance (function), but we get the idea.\n",
    "\n",
    "Now it is time to find eigenvalues & eigenvectors. There is a lot of math there behind those 2 words, but we don't need to worry just yet about that.\n",
    "\n",
    "Again, use search engine or `numpy` documentation to find which module, and which function give you back the eigenvectors & eigenvalues.\n",
    "\n",
    "> NOTE: the step for sorting is actually implemented inside the `numpy` utility, so the o/p is sorted descendingly w/ respect to eigenvalues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: search the numpy documentation, or use search engine to find how to use\n",
    "# numpy to find eigenvalues & eigenvectors\n",
    "eig_vals, eig_vects = np.linalg.eig(cov)\n",
    "eig_vals, eig_vects\n",
    "# TODO: read in eigenvalues & eigenvectors and check against your results\n",
    "e_vals = np.load(os.path.join(DATA_PATH, EIG_VAL_FILE))\n",
    "e_vect = np.load(os.path.join(DATA_PATH, EIG_VECT_FILE))\n",
    "\n",
    "np.all(eig_vals == e_vals) and np.all(e_vect == eig_vects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final steps, select a number of features $k$ ranging $[1,n[$, where n is the number of dimensions (columns) you have\n",
    "\n",
    "Now slice the eigenvectors matrix for the first $k$ columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select k\n",
    "k = 4\n",
    "\n",
    "# TODO: slice up your eigenvectors matrix\n",
    "transformer = eig_vects[:, :k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using matrix multiplication (we'll search for that as well), transform the standardised set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: search how to do matrix multiplication (dot product) using numpy and\n",
    "# transform the standardised set\n",
    "pca_prod = np.dot(standard, transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(data: np.ndarray, k: int = -1):\n",
    "    \"\"\"A function to manually apply PCA on a given dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        the data set to apply PCA on, dimensions/features are on columns\n",
    "    k: int, default = -1\n",
    "        the number of features to narrow down at the end, when -1 (default) use\n",
    "        all features\n",
    "    \"\"\"\n",
    "    if k == -1:\n",
    "        _, k = data.shape\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "\n",
    "    data = (data - mean) / std\n",
    "\n",
    "    cov = np.cov(data, rowvar=False)\n",
    "\n",
    "    _, v = np.linalg.eig(cov)\n",
    "\n",
    "    return data @ v[:, :k]  # alternative for np.dot(data, v[:, :k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we're done.\n",
    "\n",
    "Hope you enjoyed the exercise!\n",
    "\n",
    "The next cell is some code outside from the content of the nanodegree, but it is to validate against the results we obtained\n",
    "\n",
    "> NOTE: the next cell applies as $k=n$, i.e. on the full feature set, so to validate against it, either you'd repeat your last step, by setting `k` to the number of features (columns), or set `n_components=k` in the arguments to `PCA` instantiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.69976873, -0.0957599 , -0.38522941, -0.07924949],\n",
       "       [-0.63847181, -0.7477542 , -0.29299551,  0.33035357],\n",
       "       [-0.10795215, -1.43832606,  0.76020549, -0.09370268],\n",
       "       [-0.05389867,  2.1457436 ,  0.42226445,  0.06273794],\n",
       "       [-1.8994461 ,  0.13609655, -0.50424503, -0.22013935]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "std_data = scaler.fit_transform(raw)\n",
    "decomposer = PCA() # you may set `n_components` as arguments here\n",
    "result = decomposer.fit_transform(std_data)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you\n",
    "\n",
    "## Good Luck\n",
    "\n",
    "## Have Fun\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
